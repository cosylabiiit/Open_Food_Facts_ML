{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cudf\n",
    "df=cudf.read_csv('/home/pavit21178/Nalin_OFF/Data/en.openfoodfacts.org.products.csv',sep='\\t',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import chi2_contingency\n",
    "from statsmodels.stats.multitest import multipletests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,column in enumerate(df.columns):\n",
    "    print(i,column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['nova_group'].isin([1,2,3,4])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['categories_en'].value_counts().head(10).to_pandas().plot(kind='bar',title='Top 10 catogories_en',figsize=(10,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['nova_group']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories_df=df[['nova_group','categories_en']].to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove rows with values as None\n",
    "categories_df=categories_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories_df[1:10]['categories_en']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from networkx.algorithms.community import louvain_communities\n",
    "from collections import Counter\n",
    "\n",
    "# Convert to pandas DataFrame if necessary\n",
    "categories_df = df[['nova_group', 'categories_en']].to_pandas()\n",
    "\n",
    "# Remove any None entries in the 'categories_en' column\n",
    "categories_df = categories_df.dropna(subset=['categories_en'])\n",
    "\n",
    "# Count the occurrences of each category\n",
    "all_categories = [cat.strip() for entry in categories_df['categories_en'] for cat in entry.split(',')]\n",
    "category_counts = Counter(all_categories)\n",
    "\n",
    "# Get the 300 most common categories (fewer to reduce clutter)\n",
    "top_300_categories = set([category for category, count in category_counts.most_common(50)])\n",
    "\n",
    "# Filter the DataFrame to only include entries with the most prevalent categories\n",
    "categories_df['filtered_categories'] = categories_df['categories_en'].apply(\n",
    "    lambda entry: ','.join([cat for cat in entry.split(',') if cat.strip() in top_300_categories])\n",
    ")\n",
    "\n",
    "# Set up the figure with subplots (2 rows, 2 columns for NOVA classes 1-4)\n",
    "fig, axes = plt.subplots(2, 2, figsize=(30, 30))\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Loop over each nova_group (Class 1-4)\n",
    "for i, nova_group in enumerate(sorted(categories_df['nova_group'].unique())):\n",
    "    # Extract subset for the current nova_group\n",
    "    subset_df = categories_df[categories_df['nova_group'] == nova_group]['filtered_categories']\n",
    "    \n",
    "    # Create a directed graph for the current nova_group\n",
    "    G = nx.DiGraph()\n",
    "    \n",
    "    # Process each entry in the subset DataFrame\n",
    "    for entry in subset_df:\n",
    "        if entry:  # Ensure the entry is not empty\n",
    "            categories_list = [cat for cat in dict.fromkeys(entry.split(',')) if ':' not in cat]\n",
    "            for j in range(len(categories_list) - 1):\n",
    "                G.add_edge(categories_list[j], categories_list[j + 1])\n",
    "    \n",
    "    # Prune nodes by degree (keep only nodes with degree > 4)\n",
    "    G = G.subgraph([n for n, d in G.degree() if d > 4])\n",
    "    \n",
    "    # Use Louvain community detection for clustering\n",
    "    communities = louvain_communities(G, seed=42)\n",
    "    community_map = {}\n",
    "    for k, comm in enumerate(communities):\n",
    "        for node in comm:\n",
    "            community_map[node] = k\n",
    "    \n",
    "    # Limit edges to top connections by edge weight or frequency\n",
    "    threshold = 0.5  # Stricter threshold to reduce edge clutter\n",
    "    top_edges = [(u, v) for u, v, d in G.edges(data=True) if d.get('weight', 1) > threshold]\n",
    "    G = G.edge_subgraph(top_edges)\n",
    "    \n",
    "    # Node size by degree with limited range (adjusted scaling)\n",
    "    node_sizes = [min(1200, max(300, G.degree(node) * 150)) for node in G.nodes]\n",
    "    \n",
    "    # Use a lighter color palette (e.g., 'Pastel1')\n",
    "    pos = nx.spring_layout(G, k=1.5, iterations=150)  # Further increased spacing and iterations\n",
    "    \n",
    "    # Color nodes by community with a lighter colormap (e.g., 'Pastel1')\n",
    "    nx.draw_networkx_nodes(G, pos, ax=axes[i], node_size=node_sizes,\n",
    "                           node_color=[community_map[node] for node in G.nodes],\n",
    "                           cmap=plt.cm.Set3, alpha=0.85)  # Lighter colormap\n",
    "    \n",
    "    # Draw edges with high transparency and reduced width\n",
    "    nx.draw_networkx_edges(G, pos, ax=axes[i], alpha=0.05, arrowstyle='-|>', arrowsize=10, width=0.8)  # More transparent edges\n",
    "    \n",
    "    # Show labels only for high-degree nodes (adjusted threshold)\n",
    "    high_degree_nodes = [node for node in G.nodes if G.degree(node) > 4]  # Increased threshold for labeling\n",
    "    nx.draw_networkx_labels(G, pos, ax=axes[i], labels={node: node for node in high_degree_nodes},\n",
    "                            font_size=16, font_color='black')  # Larger font size\n",
    "    \n",
    "    # Set the title for each subplot\n",
    "    axes[i].set_title(f'NOVA {nova_group}', fontsize=30)\n",
    "    axes[i].axis('off')\n",
    "\n",
    "# Adjust layout for better spacing between plots\n",
    "plt.tight_layout(pad=3.0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_and_display_graph(nova_group):\n",
    "    # Extract subset for the current nova_group\n",
    "    subset_df = categories_df[categories_df['nova_group'] == nova_group]['categories_en']\n",
    "    \n",
    "    # Create a directed graph for the current nova_group\n",
    "    G = nx.DiGraph()\n",
    "    \n",
    "    # Process each entry in the subset DataFrame\n",
    "    for entry in subset_df:\n",
    "        # Split the entry into a list of unique categories and filter out those with colons\n",
    "        categories_list = [cat for cat in dict.fromkeys(entry.split(',')) if ':' not in cat]\n",
    "        \n",
    "        # Add edges to the graph based on the category order\n",
    "        for i in range(len(categories_list) - 1):\n",
    "            G.add_edge(categories_list[i], categories_list[i + 1])\n",
    "    \n",
    "    # Draw the graph\n",
    "    plt.figure(figsize=(12, 8))  # Adjust the figure size as needed\n",
    "    pos = nx.spring_layout(G, k=1)  # Use spring layout for better spacing\n",
    "    nx.draw(G, pos, with_labels=True, node_size=3000, node_color='skyblue', font_size=10, font_weight='bold', arrowstyle='-|>', arrowsize=20)\n",
    "    plt.title(f'Category Order Graph - Class {nova_group}')\n",
    "    plt.show()\n",
    "\n",
    "# Process each unique nova_group and create/display the graph\n",
    "for nova_group in sorted(categories_df['nova_group'].unique()):\n",
    "    create_and_display_graph(nova_group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import plotly.graph_objects as go\n",
    "categories_df=categories_df[1:500]\n",
    "\n",
    "\n",
    "# Initialize defaultdict to count transitions\n",
    "transition_counts = defaultdict(lambda: defaultdict(int))\n",
    "\n",
    "# Process each entry in the DataFrame\n",
    "for _, row in categories_df.iterrows():\n",
    "    nova_group = row['nova_group']\n",
    "    categories_list = [cat for cat in dict.fromkeys(row['categories_en'].split(',')) if ':' not in cat]\n",
    "    \n",
    "    # Count the transitions for each class\n",
    "    for i in range(len(categories_list) - 1):\n",
    "        transition_counts[nova_group][(categories_list[i], categories_list[i + 1])] += 1\n",
    "\n",
    "# Prepare data for Sankey diagrams\n",
    "all_nodes = set()\n",
    "for transitions in transition_counts.values():\n",
    "    all_nodes.update(set(sum(transitions.keys(), ())))\n",
    "\n",
    "all_nodes = list(all_nodes)\n",
    "node_indices = {node: i for i, node in enumerate(all_nodes)}\n",
    "\n",
    "# Generate and display Sankey diagram for each class\n",
    "for nova_group, transitions in transition_counts.items():\n",
    "    source_indices = [node_indices[transition[0]] for transition in transitions.keys()]\n",
    "    target_indices = [node_indices[transition[1]] for transition in transitions.keys()]\n",
    "    values = list(transitions.values())\n",
    "\n",
    "    sankey_fig = go.Figure(go.Sankey(\n",
    "        node=dict(\n",
    "            pad=15,\n",
    "            thickness=20,\n",
    "            line=dict(color=\"black\", width=0.5),\n",
    "            label=all_nodes\n",
    "        ),\n",
    "        link=dict(\n",
    "            source=source_indices,\n",
    "            target=target_indices,\n",
    "            value=values\n",
    "        )\n",
    "    ))\n",
    "\n",
    "    sankey_fig.update_layout(\n",
    "        title_text=f\"Category Transition Sankey Diagram - Class {nova_group}\",\n",
    "        font_size=8,\n",
    "        width=1200,  # Adjust width as needed\n",
    "        height=800   # Adjust height as needed\n",
    "    )\n",
    "    sankey_fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,column in enumerate(df.columns):\n",
    "    print(i,column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['countries_en'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries_en=df[['nova_group','countries_en']].to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries_en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries_en=df[['nova_group','countries_en']].to_pandas()\n",
    "countries_en = countries_en.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries_en.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries_en=df[['nova_group','countries_en']].to_pandas()\n",
    "countries_en = countries_en.dropna()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries_en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Initialize an empty list to store expanded data\n",
    "expanded_data = []\n",
    "\n",
    "# Iterate over each row in the DataFrame\n",
    "for index, row in countries_en.iterrows():\n",
    "    nova_group = row['nova_group']\n",
    "    countries = [country.strip() for country in row['countries_en'].split(',') if country.strip()]\n",
    "    \n",
    "    # Create a new entry for each country in the list\n",
    "    for country in countries:\n",
    "        expanded_data.append({'nova_group': nova_group, 'countries_en': country})\n",
    "\n",
    "# Create a new DataFrame from the expanded data\n",
    "expanded_df = pd.DataFrame(expanded_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expanded_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Initialize an empty list to store expanded data\n",
    "expanded_data = []\n",
    "\n",
    "# Iterate over each row in the DataFrame\n",
    "for index, row in countries_en.iterrows():\n",
    "    nova_group = row['nova_group']\n",
    "    countries = [country.strip() for country in row['countries_en'].split(',') if country.strip()]\n",
    "    \n",
    "    # Create a new entry for each country in the list\n",
    "    for country in countries:\n",
    "        expanded_data.append({'nova_group': nova_group, 'countries_en': country})\n",
    "\n",
    "# Create a new DataFrame from the expanded data\n",
    "expanded_df = pd.DataFrame(expanded_data)\n",
    "\n",
    "# Define colors for the chart\n",
    "colors = plt.get_cmap('tab10').colors\n",
    "\n",
    "# Function to format the labels without the percentage symbol\n",
    "def without_percentage(pct):\n",
    "    return '{:.0f}%'.format(pct)\n",
    "\n",
    "# Get the unique nova_group values and sort them in numerical order\n",
    "sorted_nova_groups = sorted(expanded_df['nova_group'].unique())\n",
    "\n",
    "# Create a 2x2 subplot\n",
    "fig, axs = plt.subplots(2, 2, figsize=(14, 12))\n",
    "\n",
    "# Flatten the axs array for easy iteration\n",
    "axs = axs.flatten()\n",
    "\n",
    "# Iterate over each sorted `nova_group` and the corresponding axes\n",
    "for i, (nova_group, ax) in enumerate(zip(sorted_nova_groups, axs)):\n",
    "    # Get the top 10 countries and their counts for this nova_group\n",
    "    group_data = expanded_df[expanded_df['nova_group'] == nova_group]\n",
    "    top_countries = group_data['countries_en'].value_counts().head(10)\n",
    "    \n",
    "    # Plot the doughnut chart\n",
    "    wedges, _, autotexts = ax.pie(\n",
    "        top_countries, \n",
    "        autopct=without_percentage,  # Use the custom function to remove %\n",
    "        startangle=90, \n",
    "        colors=colors, \n",
    "        wedgeprops={'edgecolor': 'white'},\n",
    "        pctdistance=0.85,  # Move percentage labels slightly closer to the center\n",
    "        explode=[0.05]*len(top_countries),  # Explode all wedges slightly for clarity\n",
    "    )\n",
    "    \n",
    "    # Customize percentage text size and color\n",
    "    for autotext in autotexts:\n",
    "        autotext.set_fontsize(10)  # Increase font size for readability\n",
    "        autotext.set_weight('bold')  # Bold font for visibility\n",
    "        autotext.set_color('black')  # Set to black for clarity\n",
    "        autotext.set_ha('center')  # Centrally align text horizontally\n",
    "        autotext.set_va('center')  # Centrally align text vertically\n",
    "\n",
    "    # Add a circle at the center to create the doughnut hole\n",
    "    centre_circle = plt.Circle((0,0),0.70,fc='white')\n",
    "    ax.add_artist(centre_circle)\n",
    "\n",
    "    # Add a legend outside the plot for each subplot\n",
    "    ax.legend(wedges, top_countries.index, title=\"Country\", loc=\"center left\", bbox_to_anchor=(1, 0, 0.5, 1))\n",
    "    \n",
    "    # Set title for the chart as the nova_group\n",
    "    ax.set_title(f'NOVA {nova_group}', fontsize=14)\n",
    "\n",
    "    # Ensure equal aspect ratio for the doughnut chart\n",
    "    ax.axis('equal')\n",
    "\n",
    "# Adjust layout to make room for the legends\n",
    "plt.tight_layout()\n",
    "\n",
    "# Display the full plot with 4 subplots\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contingency_table = pd.crosstab(expanded_df['nova_group'], expanded_df['countries_en'])\n",
    "\n",
    "# Display contingency table\n",
    "print(\"Contingency Table:\")\n",
    "print(contingency_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chi-square test of independence\n",
    "chi2, p, dof, expected = chi2_contingency(contingency_table)\n",
    "\n",
    "# Display results\n",
    "print(\"\\nChi-square Test Results:\")\n",
    "print(f\"Chi-square statistic: {chi2}\")\n",
    "print(f\"P-value: {p}\")\n",
    "print(f\"Degrees of freedom: {dof}\")\n",
    "\n",
    "alpha = 0.05\n",
    "n_tests = contingency_table.size\n",
    "reject, corrected_p_values, _, _ = multipletests(p, alpha=alpha, method='bonferroni')\n",
    "\n",
    "# Display corrected p-values\n",
    "print(\"\\nCorrected P-values:\")\n",
    "print(corrected_p_values)\n",
    "\n",
    "\n",
    "n = contingency_table.values.sum()\n",
    "\n",
    "# Number of rows and columns\n",
    "r, k = contingency_table.shape\n",
    "\n",
    "# Calculate Cramér's V\n",
    "V = np.sqrt(chi2 / n / min(k - 1, r - 1))\n",
    "\n",
    "print(f\"Cramér's V: {V}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_brands = df[['nova_group', 'brands']].to_pandas()\n",
    "df_brands = df_brands.dropna()\n",
    "\n",
    "df_brands['brands'].value_counts().head(10).plot(kind='bar',title='Top 10 brands_en',figsize=(10,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contingency_table = pd.crosstab(df_brands['nova_group'], df_brands['brands'])\n",
    "\n",
    "# Display contingency table\n",
    "print(\"Contingency Table:\")\n",
    "print(contingency_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chi-square test of independence\n",
    "chi2, p, dof, expected = chi2_contingency(contingency_table)\n",
    "\n",
    "# Display results\n",
    "print(\"\\nChi-square Test Results:\")\n",
    "print(f\"Chi-square statistic: {chi2}\")\n",
    "print(f\"P-value: {p}\")\n",
    "print(f\"Degrees of freedom: {dof}\")\n",
    "\n",
    "alpha = 0.05\n",
    "n_tests = contingency_table.size\n",
    "reject, corrected_p_values, _, _ = multipletests(p, alpha=alpha, method='bonferroni')\n",
    "\n",
    "# Display corrected p-values\n",
    "print(\"\\nCorrected P-values:\")\n",
    "print(corrected_p_values)\n",
    "\n",
    "n = contingency_table.values.sum()\n",
    "\n",
    "# Number of rows and columns\n",
    "r, k = contingency_table.shape\n",
    "\n",
    "# Calculate Cramér's V\n",
    "V = np.sqrt(chi2 / n / min(k - 1, r - 1))\n",
    "\n",
    "print(f\"Cramér's V: {V}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Example DataFrame (replace with your actual data)\n",
    "allergens_df = df[['nova_group', 'allergens']].to_pandas()\n",
    "# Drop rows with missing values in 'allergens'\n",
    "allergens_df = allergens_df.dropna(subset=['allergens'])\n",
    "\n",
    "# Initialize an empty list to store expanded data\n",
    "expanded_data = []\n",
    "\n",
    "# Regex pattern to match allergen format 'en:allergen'\n",
    "pattern = re.compile(r'^en:(\\w+)$')\n",
    "\n",
    "# Iterate over each row in the DataFrame\n",
    "for index, row in allergens_df.iterrows():\n",
    "    nova_group = row['nova_group']\n",
    "    allergens_list = row['allergens'].split(',')\n",
    "    \n",
    "    # Process each allergen in the list\n",
    "    for allergen in allergens_list:\n",
    "        match = pattern.match(allergen.strip())\n",
    "        if match:\n",
    "            expanded_data.append({'nova_group': nova_group, 'allergen': match.group(1)})\n",
    "\n",
    "# Create a new DataFrame from the expanded data\n",
    "expanded_df = pd.DataFrame(expanded_data)\n",
    "\n",
    "# Display the expanded DataFrame\n",
    "print(expanded_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allergens_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Example DataFrame (replace with your actual data)\n",
    "allergens_df = df[['nova_group', 'allergens']].to_pandas()\n",
    "# Drop rows with missing values in 'allergens'\n",
    "allergens_df = allergens_df.dropna(subset=['allergens'])\n",
    "\n",
    "# Initialize an empty list to store expanded data\n",
    "expanded_data = []\n",
    "\n",
    "# Regex pattern to match allergen format 'en:allergen'\n",
    "pattern = re.compile(r'^en:(\\w+)$')\n",
    "\n",
    "# Iterate over each row in the DataFrame\n",
    "for index, row in allergens_df.iterrows():\n",
    "    nova_group = row['nova_group']\n",
    "    allergens_list = row['allergens'].split(',')\n",
    "    \n",
    "    # Process each allergen in the list\n",
    "    for allergen in allergens_list:\n",
    "        match = pattern.match(allergen.strip())\n",
    "        if match:\n",
    "            expanded_data.append({'nova_group': nova_group, 'allergen': match.group(1)})\n",
    "\n",
    "# Create a new DataFrame from the expanded data\n",
    "expanded_df = pd.DataFrame(expanded_data)\n",
    "\n",
    "\n",
    "# Define colors for the chart\n",
    "colors = plt.get_cmap('tab10').colors\n",
    "\n",
    "# Function to format the labels without the percentage symbol\n",
    "def without_percentage(pct):\n",
    "    return '{:.0f}%'.format(pct)\n",
    "\n",
    "# Get the unique nova_group values and sort them in numerical order\n",
    "sorted_nova_groups = sorted(expanded_df['nova_group'].unique())\n",
    "\n",
    "# Create a 2x2 subplot\n",
    "fig, axs = plt.subplots(2, 2, figsize=(14, 12))\n",
    "\n",
    "# Flatten the axs array for easy iteration\n",
    "axs = axs.flatten()\n",
    "\n",
    "# Iterate over each sorted `nova_group` and the corresponding axes\n",
    "for i, (nova_group, ax) in enumerate(zip(sorted_nova_groups, axs)):\n",
    "    # Get the top 10 countries and their counts for this nova_group\n",
    "    group_data = expanded_df[expanded_df['nova_group'] == nova_group]\n",
    "    top_countries = group_data['allergen'].value_counts().head(10)\n",
    "    \n",
    "    # Plot the doughnut chart\n",
    "    wedges, _, autotexts = ax.pie(\n",
    "        top_countries, \n",
    "        autopct=without_percentage,  # Use the custom function to remove %\n",
    "        startangle=90, \n",
    "        colors=colors, \n",
    "        wedgeprops={'edgecolor': 'white'},\n",
    "        pctdistance=0.85,  # Move percentage labels slightly closer to the center\n",
    "        explode=[0.05]*len(top_countries),  # Explode all wedges slightly for clarity\n",
    "    )\n",
    "    \n",
    "    # Customize percentage text size and color\n",
    "    for autotext in autotexts:\n",
    "        autotext.set_fontsize(10)  # Increase font size for readability\n",
    "        autotext.set_weight('bold')  # Bold font for visibility\n",
    "        autotext.set_color('black')  # Set to black for clarity\n",
    "        autotext.set_ha('center')  # Centrally align text horizontally\n",
    "        autotext.set_va('center')  # Centrally align text vertically\n",
    "\n",
    "    # Add a circle at the center to create the doughnut hole\n",
    "    centre_circle = plt.Circle((0,0),0.70,fc='white')\n",
    "    ax.add_artist(centre_circle)\n",
    "\n",
    "    # Add a legend outside the plot for each subplot\n",
    "    ax.legend(wedges, top_countries.index, title=\"Allergen\", loc=\"center left\", bbox_to_anchor=(1, 0, 0.5, 1))\n",
    "    \n",
    "    # Set title for the chart as the nova_group\n",
    "    ax.set_title(f'NOVA {nova_group}', fontsize=14)\n",
    "\n",
    "    # Ensure equal aspect ratio for the doughnut chart\n",
    "    ax.axis('equal')\n",
    "\n",
    "# Adjust layout to make room for the legends\n",
    "plt.tight_layout()\n",
    "\n",
    "# Display the full plot with 4 subplots\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expanded_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contingency_table = pd.crosstab(expanded_df['nova_group'], expanded_df['allergen'])\n",
    "\n",
    "# Display contingency table\n",
    "print(\"Contingency Table:\")\n",
    "print(contingency_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chi-square test of independence\n",
    "chi2, p, dof, expected = chi2_contingency(contingency_table)\n",
    "\n",
    "# Display results\n",
    "print(\"\\nChi-square Test Results:\")\n",
    "print(f\"Chi-square statistic: {chi2}\")\n",
    "print(f\"P-value: {p}\")\n",
    "print(f\"Degrees of freedom: {dof}\")\n",
    "alpha = 0.05\n",
    "n_tests = contingency_table.size\n",
    "reject, corrected_p_values, _, _ = multipletests(p, alpha=alpha, method='bonferroni')\n",
    "\n",
    "# Display corrected p-values\n",
    "print(\"\\nCorrected P-values:\")\n",
    "print(corrected_p_values)\n",
    "\n",
    "n = contingency_table.values.sum()\n",
    "\n",
    "# Number of rows and columns\n",
    "r, k = contingency_table.shape\n",
    "\n",
    "# Calculate Cramér's V\n",
    "V = np.sqrt(chi2 / n / min(k - 1, r - 1))\n",
    "\n",
    "print(f\"Cramér's V: {V}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['nova_group', 'main_category_en']].to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_categories = df[['nova_group', 'main_category_en']].to_pandas()\n",
    "df_categories = df_categories.dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contingency_table = pd.crosstab(df_categories['nova_group'], df_categories['main_category_en'])\n",
    "\n",
    "# # Display contingency table\n",
    "# print(\"Contingency Table:\")\n",
    "# print(contingency_table)\n",
    "# Chi-square test of independence\n",
    "chi2, p, dof, expected = chi2_contingency(contingency_table)\n",
    "\n",
    "# Display results\n",
    "print(\"\\nChi-square Test Results:\")\n",
    "print(f\"Chi-square statistic: {chi2}\")\n",
    "print(f\"P-value: {p}\")\n",
    "print(f\"Degrees of freedom: {dof}\")\n",
    "\n",
    "alpha = 0.05\n",
    "n_tests = contingency_table.size\n",
    "reject, corrected_p_values, _, _ = multipletests(p, alpha=alpha, method='bonferroni')\n",
    "\n",
    "# Display corrected p-values\n",
    "print(\"\\nCorrected P-values:\")\n",
    "print(corrected_p_values)\n",
    "\n",
    "\n",
    "n = contingency_table.values.sum()\n",
    "\n",
    "# Number of rows and columns\n",
    "r, k = contingency_table.shape\n",
    "\n",
    "# Calculate Cramér's V\n",
    "V = np.sqrt(chi2 / n / min(k - 1, r - 1))\n",
    "\n",
    "print(f\"Cramér's V: {V}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['food_groups_en'].value_counts().head(10).to_pandas().plot(kind='bar',title='Top 10 food_groups',figsize=(10,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_food_groups = df[['nova_group', 'food_groups_en']].to_pandas()\n",
    "df_food_groups = df_food_groups.dropna()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contingency_table\n",
    "# use bonferroni correction\n",
    "from scipy.stats import chi2_contingency\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "\n",
    "# Chi-square test of independence\n",
    "chi2, p, dof, expected = chi2_contingency(contingency_table)\n",
    "\n",
    "# Display results\n",
    "print(\"\\nChi-square Test Results:\")\n",
    "print(f\"Chi-square statistic: {chi2}\")\n",
    "print(f\"P-value: {p}\")\n",
    "print(f\"Degrees of freedom: {dof}\")\n",
    "\n",
    "# Apply Bonferroni correction\n",
    "alpha = 0.05\n",
    "n_tests = contingency_table.size\n",
    "reject, corrected_p_values, _, _ = multipletests(p, alpha=alpha, method='bonferroni')\n",
    "\n",
    "# Display corrected p-values\n",
    "print(\"\\nCorrected P-values:\")\n",
    "print(corrected_p_values)\n",
    "\n",
    "n = contingency_table.values.sum()\n",
    "\n",
    "# Number of rows and columns\n",
    "r, k = contingency_table.shape\n",
    "\n",
    "# Calculate Cramér's V\n",
    "V = np.sqrt(chi2 / n / min(k - 1, r - 1))\n",
    "\n",
    "print(f\"Cramér's V: {V}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nutriscore_grade_df = df[['nova_group','nutriscore_grade']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep only food items which have nutriscore_grade in a,b,c,d,e\n",
    "nutriscore_grade_df = nutriscore_grade_df[nutriscore_grade_df['nutriscore_grade'].isin(['a','b','c','d','e'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nutriscore_grade_df_pandas = nutriscore_grade_df.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming df is your DataFrame\n",
    "contingency_table = pd.crosstab(nutriscore_grade_df_pandas['nova_group'], nutriscore_grade_df_pandas['nutriscore_grade'])\n",
    "print(contingency_table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "35294+  55070 + 88337 + 137484 + 98996"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "98996/415181*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nutriscore_grade_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "nutriscore_grade_df = df[['nova_group','nutriscore_grade']]\n",
    "# keep only food items which have nutriscore_grade in a,b,c,d,e\n",
    "nutriscore_grade_df = nutriscore_grade_df[nutriscore_grade_df['nutriscore_grade'].isin(['a','b','c','d','e'])]\n",
    "nutriscore_grade_df_pandas = nutriscore_grade_df.to_pandas()\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming df is your DataFrame\n",
    "contingency_table = pd.crosstab(nutriscore_grade_df_pandas['nova_group'], nutriscore_grade_df_pandas['nutriscore_grade'])\n",
    "print(contingency_table)\n",
    "\n",
    "contingency_table.columns = ['A', 'B', 'C', 'D', 'E']\n",
    "\n",
    "# Plot the contingency table as a stacked bar chart\n",
    "contingency_table.plot(kind='bar', stacked=True)\n",
    "\n",
    "# Set the y-axis label\n",
    "plt.ylabel('Count')\n",
    "\n",
    "# Remove the title\n",
    "plt.title('')\n",
    "\n",
    "# Customize the legend with uppercase grades\n",
    "plt.legend(title='Nutri-Score Grade')\n",
    "\n",
    "# Customize the x-ticks to display as 'NOVA 1', 'NOVA 2', etc. and keep them horizontal\n",
    "plt.xticks(ticks=range(len(contingency_table.index)), labels=['NOVA 1', 'NOVA 2', 'NOVA 3', 'NOVA 4'], rotation=0)\n",
    "\n",
    "# Remove the x-axis label\n",
    "plt.xlabel('')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# use bonferroni correction\n",
    "from scipy.stats import chi2_contingency\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "\n",
    "# Chi-square test of independence\n",
    "chi2, p, dof, expected = chi2_contingency(contingency_table)\n",
    "\n",
    "# Display results\n",
    "print(\"\\nChi-square Test Results:\")\n",
    "print(f\"Chi-square statistic: {chi2}\")\n",
    "print(f\"P-value: {p}\")\n",
    "print(f\"Degrees of freedom: {dof}\")\n",
    "\n",
    "alpha = 0.05\n",
    "n_tests = contingency_table.size\n",
    "reject, corrected_p_values, _, _ = multipletests(p, alpha=alpha, method='bonferroni')\n",
    "\n",
    "\n",
    "print(\"\\nCorrected P-values:\")\n",
    "print(corrected_p_values)\n",
    "\n",
    "n = contingency_table.values.sum()\n",
    "\n",
    "r, k = contingency_table.shape\n",
    "\n",
    "\n",
    "V = np.sqrt(chi2 / n / min(k - 1, r - 1))\n",
    "\n",
    "print(f\"Cramér's V: {V}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ecoscore_grade_df = df[['nova_group','ecoscore_grade']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ecoscore_grade_df['ecoscore_grade'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep only food items which have nutriscore_grade in a,b,c,d,e\n",
    "ecoscore_grade_df = ecoscore_grade_df[ecoscore_grade_df['ecoscore_grade'].isin(['a','b','c','d','e'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ecoscore_grade_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ecoscore_grade_df_pandas = ecoscore_grade_df.to_pandas()\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming df is your DataFrame\n",
    "contingency_table = pd.crosstab(ecoscore_grade_df_pandas['nova_group'], ecoscore_grade_df_pandas['ecoscore_grade'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contingency_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "12811+\t74865+\t50302+\t54488+\t19874"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "19874/212340*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "ecoscore_grade_df = df[['nova_group','ecoscore_grade']]\n",
    "ecoscore_grade_df['ecoscore_grade'].value_counts()\n",
    "# keep only food items which have nutriscore_grade in a,b,c,d,e\n",
    "ecoscore_grade_df = ecoscore_grade_df[ecoscore_grade_df['ecoscore_grade'].isin(['a','b','c','d','e'])]\n",
    "ecoscore_grade_df_pandas = ecoscore_grade_df.to_pandas()\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming df is your DataFrame\n",
    "contingency_table = pd.crosstab(ecoscore_grade_df_pandas['nova_group'], ecoscore_grade_df_pandas['ecoscore_grade'])\n",
    "contingency_table.columns = ['A', 'B', 'C', 'D', 'E']\n",
    "\n",
    "# Plot the contingency table as a stacked bar chart\n",
    "contingency_table.plot(kind='bar', stacked=True)\n",
    "\n",
    "# Set the y-axis label\n",
    "plt.ylabel('Count')\n",
    "\n",
    "# Remove the title\n",
    "plt.title('')\n",
    "\n",
    "# Customize the legend\n",
    "plt.legend(title='Eco-Score Grade')\n",
    "\n",
    "# Customize the x-ticks to display as 'NOVA 1', 'NOVA 2', etc. and keep them horizontal\n",
    "plt.xticks(ticks=range(len(contingency_table.index)), labels=['NOVA 1', 'NOVA 2', 'NOVA 3', 'NOVA 4'], rotation=0)\n",
    "\n",
    "# Remove the x-axis label\n",
    "plt.xlabel('')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from scipy.stats import chi2_contingency\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "\n",
    "chi2, p, dof, expected = chi2_contingency(contingency_table)\n",
    "\n",
    "print(\"\\nChi-square Test Results:\")\n",
    "print(f\"Chi-square statistic: {chi2}\")\n",
    "print(f\"P-value: {p}\")\n",
    "print(f\"Degrees of freedom: {dof}\")\n",
    "\n",
    "alpha = 0.05\n",
    "n_tests = contingency_table.size\n",
    "reject, corrected_p_values, _, _ = multipletests(p, alpha=alpha, method='bonferroni')\n",
    "\n",
    "print(\"\\nCorrected P-values:\")\n",
    "print(corrected_p_values)\n",
    "\n",
    "n = contingency_table.values.sum()\n",
    "\n",
    "r, k = contingency_table.shape\n",
    "\n",
    "V = np.sqrt(chi2 / n / min(k - 1, r - 1))\n",
    "\n",
    "print(f\"Cramér's V: {V}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
