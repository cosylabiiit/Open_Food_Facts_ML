{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cudf\n",
    "\n",
    "data=cudf.read_csv(\"/home/pavit21178/Nalin_OFF/Data/OFF_FNDDS_COLS_NOVA.csv\",index_col=0)\n",
    "# keep only data w 1,2,3,4 in the novaclass column\n",
    "data = data[data['novaclass'].isin([1,2,3,4])]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use random forest to predict the NOVA group\n",
    "from cuml.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from cuml.metrics import accuracy_score\n",
    "\n",
    "X = data.drop('novaclass', axis=1)\n",
    "y=data['novaclass']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cuml.preprocessing import SimpleImputer\n",
    "import cupy as cp\n",
    "imp_mean = SimpleImputer(missing_values=cp.nan, strategy='mean')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cuml.preprocessing import StandardScaler\n",
    "from cuml.preprocessing import SimpleImputer\n",
    "import cupy as cp\n",
    "imp_mean = SimpleImputer(missing_values=cp.nan, strategy='mean')\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "X_train=imp_mean.fit_transform(X_train)\n",
    "X_test=imp_mean.transform(X_test)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n"
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "X_train_np=X_train.to_pandas()\n",
    "X_test_np=X_test.to_pandas()\n",
    "y_train_np=y_train.to_pandas()\n",
    "y_test_np=y_test.to_pandas()\n",
    "lgbm=LGBMClassifier(verbose=-1,device='gpu')\n",
    "lgbm.fit(X_train_np,y_train_np)\n",
    "y_pred=lgbm.predict(X_test_np)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7624432444572449\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.78      0.62      0.69     20092\n",
      "         2.0       0.88      0.57      0.70     11288\n",
      "         3.0       0.70      0.38      0.49     34605\n",
      "         4.0       0.76      0.93      0.84    109030\n",
      "\n",
      "    accuracy                           0.76    175015\n",
      "   macro avg       0.78      0.63      0.68    175015\n",
      "weighted avg       0.76      0.76      0.74    175015\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test,y_pred))\n",
    "y_test_np=y_test.to_numpy()\n",
    "# y_pred_np=y_pred.to_numpy()\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test_np, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'boosting_type': ['gbdt', 'dart'],           # Boosting type: Gradient Boosting Decision Tree (GBDT) or Dropouts meet Multiple Additive Regression Trees (DART)\n",
    "    'num_leaves': [31, 63, 127],                 # Number of leaves in one tree, higher values can increase accuracy but also increase risk of overfitting\n",
    "    'max_depth': [-1, 10, 20, 30],               # Maximum tree depth for base learners, -1 means no limit\n",
    "    'learning_rate': [0.01, 0.05, 0.1],          # Learning rate: smaller values lead to better accuracy but require more training rounds\n",
    "    'n_estimators': [100, 500, 1000,2000,3000,4000,5000,10000,20000],            # Number of boosted trees to fit\n",
    "    'subsample': [0.6, 0.8, 1.0],                # Fraction of samples used for fitting individual base learners\n",
    "    'colsample_bytree': [0.6, 0.8, 1.0],         # Fraction of features used for fitting individual base learners\n",
    "    'reg_alpha': [0, 0.1, 1],                    # L1 regularization term on weights\n",
    "    'reg_lambda': [0, 0.1, 1],                   # L2 regularization term on weights\n",
    "    'min_split_gain': [0, 0.01, 0.1],            # Minimum loss reduction required to make a further partition on a leaf node of the tree\n",
    "    'min_child_weight': [1, 5, 10],              # Minimum sum of instance weight (hessian) needed in a child (leaf)\n",
    "    'scale_pos_weight': [1, 10, 20]              # Balancing of positive and negative weights\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "[CV] END boosting_type=gbdt, colsample_bytree=0.8, learning_rate=0.05, max_depth=20, min_child_weight=5, min_split_gain=0.1, n_estimators=100, num_leaves=127, reg_alpha=0.1, reg_lambda=1, scale_pos_weight=20, subsample=1.0; total time=   9.2s\n",
      "[CV] END boosting_type=gbdt, colsample_bytree=0.8, learning_rate=0.05, max_depth=20, min_child_weight=5, min_split_gain=0.1, n_estimators=100, num_leaves=127, reg_alpha=0.1, reg_lambda=1, scale_pos_weight=20, subsample=1.0; total time=   9.1s\n",
      "[CV] END boosting_type=gbdt, colsample_bytree=0.8, learning_rate=0.05, max_depth=20, min_child_weight=5, min_split_gain=0.1, n_estimators=100, num_leaves=127, reg_alpha=0.1, reg_lambda=1, scale_pos_weight=20, subsample=1.0; total time=   9.1s\n",
      "[CV] END boosting_type=gbdt, colsample_bytree=0.8, learning_rate=0.05, max_depth=20, min_child_weight=5, min_split_gain=0.1, n_estimators=100, num_leaves=127, reg_alpha=0.1, reg_lambda=1, scale_pos_weight=20, subsample=1.0; total time=   9.6s\n",
      "[CV] END boosting_type=gbdt, colsample_bytree=0.8, learning_rate=0.05, max_depth=20, min_child_weight=5, min_split_gain=0.1, n_estimators=100, num_leaves=127, reg_alpha=0.1, reg_lambda=1, scale_pos_weight=20, subsample=1.0; total time=  10.1s\n",
      "[CV] END boosting_type=gbdt, colsample_bytree=0.8, learning_rate=0.1, max_depth=20, min_child_weight=5, min_split_gain=0, n_estimators=500, num_leaves=63, reg_alpha=0, reg_lambda=0.1, scale_pos_weight=10, subsample=1.0; total time=  24.8s\n",
      "[CV] END boosting_type=gbdt, colsample_bytree=0.8, learning_rate=0.1, max_depth=20, min_child_weight=5, min_split_gain=0, n_estimators=500, num_leaves=63, reg_alpha=0, reg_lambda=0.1, scale_pos_weight=10, subsample=1.0; total time=  22.9s\n",
      "[CV] END boosting_type=gbdt, colsample_bytree=0.8, learning_rate=0.1, max_depth=20, min_child_weight=5, min_split_gain=0, n_estimators=500, num_leaves=63, reg_alpha=0, reg_lambda=0.1, scale_pos_weight=10, subsample=1.0; total time=  23.7s\n",
      "[CV] END boosting_type=gbdt, colsample_bytree=0.8, learning_rate=0.1, max_depth=20, min_child_weight=5, min_split_gain=0, n_estimators=500, num_leaves=63, reg_alpha=0, reg_lambda=0.1, scale_pos_weight=10, subsample=1.0; total time=  23.1s\n",
      "[CV] END boosting_type=gbdt, colsample_bytree=0.8, learning_rate=0.1, max_depth=20, min_child_weight=5, min_split_gain=0, n_estimators=500, num_leaves=63, reg_alpha=0, reg_lambda=0.1, scale_pos_weight=10, subsample=1.0; total time=  25.7s\n",
      "[CV] END boosting_type=gbdt, colsample_bytree=0.8, learning_rate=0.1, max_depth=-1, min_child_weight=1, min_split_gain=0, n_estimators=1000, num_leaves=127, reg_alpha=1, reg_lambda=0.1, scale_pos_weight=1, subsample=0.8; total time= 1.2min\n",
      "[CV] END boosting_type=gbdt, colsample_bytree=0.8, learning_rate=0.1, max_depth=-1, min_child_weight=1, min_split_gain=0, n_estimators=1000, num_leaves=127, reg_alpha=1, reg_lambda=0.1, scale_pos_weight=1, subsample=0.8; total time= 1.1min\n",
      "[CV] END boosting_type=gbdt, colsample_bytree=0.8, learning_rate=0.1, max_depth=-1, min_child_weight=1, min_split_gain=0, n_estimators=1000, num_leaves=127, reg_alpha=1, reg_lambda=0.1, scale_pos_weight=1, subsample=0.8; total time= 1.2min\n",
      "[CV] END boosting_type=gbdt, colsample_bytree=0.8, learning_rate=0.1, max_depth=-1, min_child_weight=1, min_split_gain=0, n_estimators=1000, num_leaves=127, reg_alpha=1, reg_lambda=0.1, scale_pos_weight=1, subsample=0.8; total time= 1.1min\n",
      "[CV] END boosting_type=gbdt, colsample_bytree=0.8, learning_rate=0.1, max_depth=-1, min_child_weight=1, min_split_gain=0, n_estimators=1000, num_leaves=127, reg_alpha=1, reg_lambda=0.1, scale_pos_weight=1, subsample=0.8; total time= 1.1min\n",
      "[CV] END boosting_type=dart, colsample_bytree=0.8, learning_rate=0.05, max_depth=30, min_child_weight=10, min_split_gain=0, n_estimators=1000, num_leaves=63, reg_alpha=0.1, reg_lambda=0.1, scale_pos_weight=20, subsample=0.6; total time= 3.3min\n",
      "[CV] END boosting_type=dart, colsample_bytree=0.8, learning_rate=0.05, max_depth=30, min_child_weight=10, min_split_gain=0, n_estimators=1000, num_leaves=63, reg_alpha=0.1, reg_lambda=0.1, scale_pos_weight=20, subsample=0.6; total time= 3.3min\n",
      "[CV] END boosting_type=dart, colsample_bytree=0.8, learning_rate=0.05, max_depth=30, min_child_weight=10, min_split_gain=0, n_estimators=1000, num_leaves=63, reg_alpha=0.1, reg_lambda=0.1, scale_pos_weight=20, subsample=0.6; total time= 3.4min\n",
      "[CV] END boosting_type=dart, colsample_bytree=0.8, learning_rate=0.05, max_depth=30, min_child_weight=10, min_split_gain=0, n_estimators=1000, num_leaves=63, reg_alpha=0.1, reg_lambda=0.1, scale_pos_weight=20, subsample=0.6; total time= 3.4min\n",
      "[CV] END boosting_type=dart, colsample_bytree=0.8, learning_rate=0.05, max_depth=30, min_child_weight=10, min_split_gain=0, n_estimators=1000, num_leaves=63, reg_alpha=0.1, reg_lambda=0.1, scale_pos_weight=20, subsample=0.6; total time= 3.4min\n",
      "[CV] END boosting_type=dart, colsample_bytree=0.6, learning_rate=0.01, max_depth=30, min_child_weight=5, min_split_gain=0.01, n_estimators=500, num_leaves=63, reg_alpha=1, reg_lambda=0, scale_pos_weight=10, subsample=1.0; total time= 1.2min\n",
      "[CV] END boosting_type=dart, colsample_bytree=0.6, learning_rate=0.01, max_depth=30, min_child_weight=5, min_split_gain=0.01, n_estimators=500, num_leaves=63, reg_alpha=1, reg_lambda=0, scale_pos_weight=10, subsample=1.0; total time= 1.1min\n",
      "[CV] END boosting_type=dart, colsample_bytree=0.6, learning_rate=0.01, max_depth=30, min_child_weight=5, min_split_gain=0.01, n_estimators=500, num_leaves=63, reg_alpha=1, reg_lambda=0, scale_pos_weight=10, subsample=1.0; total time= 1.2min\n",
      "[CV] END boosting_type=dart, colsample_bytree=0.6, learning_rate=0.01, max_depth=30, min_child_weight=5, min_split_gain=0.01, n_estimators=500, num_leaves=63, reg_alpha=1, reg_lambda=0, scale_pos_weight=10, subsample=1.0; total time= 1.2min\n",
      "[CV] END boosting_type=dart, colsample_bytree=0.6, learning_rate=0.01, max_depth=30, min_child_weight=5, min_split_gain=0.01, n_estimators=500, num_leaves=63, reg_alpha=1, reg_lambda=0, scale_pos_weight=10, subsample=1.0; total time= 1.2min\n",
      "[CV] END boosting_type=gbdt, colsample_bytree=0.8, learning_rate=0.05, max_depth=20, min_child_weight=1, min_split_gain=0.1, n_estimators=500, num_leaves=31, reg_alpha=1, reg_lambda=1, scale_pos_weight=20, subsample=1.0; total time=  15.8s\n",
      "[CV] END boosting_type=gbdt, colsample_bytree=0.8, learning_rate=0.05, max_depth=20, min_child_weight=1, min_split_gain=0.1, n_estimators=500, num_leaves=31, reg_alpha=1, reg_lambda=1, scale_pos_weight=20, subsample=1.0; total time=  16.2s\n",
      "[CV] END boosting_type=gbdt, colsample_bytree=0.8, learning_rate=0.05, max_depth=20, min_child_weight=1, min_split_gain=0.1, n_estimators=500, num_leaves=31, reg_alpha=1, reg_lambda=1, scale_pos_weight=20, subsample=1.0; total time=  16.7s\n",
      "[CV] END boosting_type=gbdt, colsample_bytree=0.8, learning_rate=0.05, max_depth=20, min_child_weight=1, min_split_gain=0.1, n_estimators=500, num_leaves=31, reg_alpha=1, reg_lambda=1, scale_pos_weight=20, subsample=1.0; total time=  17.0s\n",
      "[CV] END boosting_type=gbdt, colsample_bytree=0.8, learning_rate=0.05, max_depth=20, min_child_weight=1, min_split_gain=0.1, n_estimators=500, num_leaves=31, reg_alpha=1, reg_lambda=1, scale_pos_weight=20, subsample=1.0; total time=  16.8s\n",
      "[CV] END boosting_type=gbdt, colsample_bytree=0.8, learning_rate=0.05, max_depth=-1, min_child_weight=10, min_split_gain=0.01, n_estimators=100, num_leaves=127, reg_alpha=0.1, reg_lambda=0, scale_pos_weight=1, subsample=0.6; total time=   8.9s\n",
      "[CV] END boosting_type=gbdt, colsample_bytree=0.8, learning_rate=0.05, max_depth=-1, min_child_weight=10, min_split_gain=0.01, n_estimators=100, num_leaves=127, reg_alpha=0.1, reg_lambda=0, scale_pos_weight=1, subsample=0.6; total time=   9.0s\n",
      "[CV] END boosting_type=gbdt, colsample_bytree=0.8, learning_rate=0.05, max_depth=-1, min_child_weight=10, min_split_gain=0.01, n_estimators=100, num_leaves=127, reg_alpha=0.1, reg_lambda=0, scale_pos_weight=1, subsample=0.6; total time=   8.9s\n",
      "[CV] END boosting_type=gbdt, colsample_bytree=0.8, learning_rate=0.05, max_depth=-1, min_child_weight=10, min_split_gain=0.01, n_estimators=100, num_leaves=127, reg_alpha=0.1, reg_lambda=0, scale_pos_weight=1, subsample=0.6; total time=   9.3s\n",
      "[CV] END boosting_type=gbdt, colsample_bytree=0.8, learning_rate=0.05, max_depth=-1, min_child_weight=10, min_split_gain=0.01, n_estimators=100, num_leaves=127, reg_alpha=0.1, reg_lambda=0, scale_pos_weight=1, subsample=0.6; total time=   9.3s\n",
      "[CV] END boosting_type=gbdt, colsample_bytree=1.0, learning_rate=0.05, max_depth=30, min_child_weight=10, min_split_gain=0, n_estimators=100, num_leaves=63, reg_alpha=0.1, reg_lambda=1, scale_pos_weight=1, subsample=0.8; total time=   6.2s\n",
      "[CV] END boosting_type=gbdt, colsample_bytree=1.0, learning_rate=0.05, max_depth=30, min_child_weight=10, min_split_gain=0, n_estimators=100, num_leaves=63, reg_alpha=0.1, reg_lambda=1, scale_pos_weight=1, subsample=0.8; total time=   6.1s\n",
      "[CV] END boosting_type=gbdt, colsample_bytree=1.0, learning_rate=0.05, max_depth=30, min_child_weight=10, min_split_gain=0, n_estimators=100, num_leaves=63, reg_alpha=0.1, reg_lambda=1, scale_pos_weight=1, subsample=0.8; total time=   6.2s\n",
      "[CV] END boosting_type=gbdt, colsample_bytree=1.0, learning_rate=0.05, max_depth=30, min_child_weight=10, min_split_gain=0, n_estimators=100, num_leaves=63, reg_alpha=0.1, reg_lambda=1, scale_pos_weight=1, subsample=0.8; total time=   6.2s\n",
      "[CV] END boosting_type=gbdt, colsample_bytree=1.0, learning_rate=0.05, max_depth=30, min_child_weight=10, min_split_gain=0, n_estimators=100, num_leaves=63, reg_alpha=0.1, reg_lambda=1, scale_pos_weight=1, subsample=0.8; total time=   6.2s\n",
      "[CV] END boosting_type=gbdt, colsample_bytree=0.6, learning_rate=0.1, max_depth=-1, min_child_weight=5, min_split_gain=0, n_estimators=100, num_leaves=127, reg_alpha=0.1, reg_lambda=1, scale_pos_weight=10, subsample=0.8; total time=   8.8s\n",
      "[CV] END boosting_type=gbdt, colsample_bytree=0.6, learning_rate=0.1, max_depth=-1, min_child_weight=5, min_split_gain=0, n_estimators=100, num_leaves=127, reg_alpha=0.1, reg_lambda=1, scale_pos_weight=10, subsample=0.8; total time=   8.7s\n",
      "[CV] END boosting_type=gbdt, colsample_bytree=0.6, learning_rate=0.1, max_depth=-1, min_child_weight=5, min_split_gain=0, n_estimators=100, num_leaves=127, reg_alpha=0.1, reg_lambda=1, scale_pos_weight=10, subsample=0.8; total time=   8.9s\n",
      "[CV] END boosting_type=gbdt, colsample_bytree=0.6, learning_rate=0.1, max_depth=-1, min_child_weight=5, min_split_gain=0, n_estimators=100, num_leaves=127, reg_alpha=0.1, reg_lambda=1, scale_pos_weight=10, subsample=0.8; total time=   8.9s\n",
      "[CV] END boosting_type=gbdt, colsample_bytree=0.6, learning_rate=0.1, max_depth=-1, min_child_weight=5, min_split_gain=0, n_estimators=100, num_leaves=127, reg_alpha=0.1, reg_lambda=1, scale_pos_weight=10, subsample=0.8; total time=   8.8s\n",
      "[CV] END boosting_type=gbdt, colsample_bytree=0.8, learning_rate=0.1, max_depth=-1, min_child_weight=10, min_split_gain=0.1, n_estimators=500, num_leaves=31, reg_alpha=0.1, reg_lambda=0.1, scale_pos_weight=20, subsample=0.6; total time=  15.8s\n",
      "[CV] END boosting_type=gbdt, colsample_bytree=0.8, learning_rate=0.1, max_depth=-1, min_child_weight=10, min_split_gain=0.1, n_estimators=500, num_leaves=31, reg_alpha=0.1, reg_lambda=0.1, scale_pos_weight=20, subsample=0.6; total time=  16.9s\n",
      "[CV] END boosting_type=gbdt, colsample_bytree=0.8, learning_rate=0.1, max_depth=-1, min_child_weight=10, min_split_gain=0.1, n_estimators=500, num_leaves=31, reg_alpha=0.1, reg_lambda=0.1, scale_pos_weight=20, subsample=0.6; total time=  17.3s\n",
      "[CV] END boosting_type=gbdt, colsample_bytree=0.8, learning_rate=0.1, max_depth=-1, min_child_weight=10, min_split_gain=0.1, n_estimators=500, num_leaves=31, reg_alpha=0.1, reg_lambda=0.1, scale_pos_weight=20, subsample=0.6; total time=  15.7s\n",
      "[CV] END boosting_type=gbdt, colsample_bytree=0.8, learning_rate=0.1, max_depth=-1, min_child_weight=10, min_split_gain=0.1, n_estimators=500, num_leaves=31, reg_alpha=0.1, reg_lambda=0.1, scale_pos_weight=20, subsample=0.6; total time=  15.7s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=5, estimator=LGBMClassifier(device=&#x27;gpu&#x27;, verbose=-1),\n",
       "                   param_distributions={&#x27;boosting_type&#x27;: [&#x27;gbdt&#x27;, &#x27;dart&#x27;],\n",
       "                                        &#x27;colsample_bytree&#x27;: [0.6, 0.8, 1.0],\n",
       "                                        &#x27;learning_rate&#x27;: [0.01, 0.05, 0.1],\n",
       "                                        &#x27;max_depth&#x27;: [-1, 10, 20, 30],\n",
       "                                        &#x27;min_child_weight&#x27;: [1, 5, 10],\n",
       "                                        &#x27;min_split_gain&#x27;: [0, 0.01, 0.1],\n",
       "                                        &#x27;n_estimators&#x27;: [100, 500, 1000],\n",
       "                                        &#x27;num_leaves&#x27;: [31, 63, 127],\n",
       "                                        &#x27;reg_alpha&#x27;: [0, 0.1, 1],\n",
       "                                        &#x27;reg_lambda&#x27;: [0, 0.1, 1],\n",
       "                                        &#x27;scale_pos_weight&#x27;: [1, 10, 20],\n",
       "                                        &#x27;subsample&#x27;: [0.6, 0.8, 1.0]},\n",
       "                   random_state=42, verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;RandomizedSearchCV<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.model_selection.RandomizedSearchCV.html\">?<span>Documentation for RandomizedSearchCV</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>RandomizedSearchCV(cv=5, estimator=LGBMClassifier(device=&#x27;gpu&#x27;, verbose=-1),\n",
       "                   param_distributions={&#x27;boosting_type&#x27;: [&#x27;gbdt&#x27;, &#x27;dart&#x27;],\n",
       "                                        &#x27;colsample_bytree&#x27;: [0.6, 0.8, 1.0],\n",
       "                                        &#x27;learning_rate&#x27;: [0.01, 0.05, 0.1],\n",
       "                                        &#x27;max_depth&#x27;: [-1, 10, 20, 30],\n",
       "                                        &#x27;min_child_weight&#x27;: [1, 5, 10],\n",
       "                                        &#x27;min_split_gain&#x27;: [0, 0.01, 0.1],\n",
       "                                        &#x27;n_estimators&#x27;: [100, 500, 1000],\n",
       "                                        &#x27;num_leaves&#x27;: [31, 63, 127],\n",
       "                                        &#x27;reg_alpha&#x27;: [0, 0.1, 1],\n",
       "                                        &#x27;reg_lambda&#x27;: [0, 0.1, 1],\n",
       "                                        &#x27;scale_pos_weight&#x27;: [1, 10, 20],\n",
       "                                        &#x27;subsample&#x27;: [0.6, 0.8, 1.0]},\n",
       "                   random_state=42, verbose=2)</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">best_estimator_: LGBMClassifier</label><div class=\"sk-toggleable__content fitted\"><pre>LGBMClassifier(colsample_bytree=0.8, device=&#x27;gpu&#x27;, min_child_weight=1,\n",
       "               min_split_gain=0, n_estimators=1000, num_leaves=127, reg_alpha=1,\n",
       "               reg_lambda=0.1, scale_pos_weight=1, subsample=0.8, verbose=-1)</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">LGBMClassifier</label><div class=\"sk-toggleable__content fitted\"><pre>LGBMClassifier(colsample_bytree=0.8, device=&#x27;gpu&#x27;, min_child_weight=1,\n",
       "               min_split_gain=0, n_estimators=1000, num_leaves=127, reg_alpha=1,\n",
       "               reg_lambda=0.1, scale_pos_weight=1, subsample=0.8, verbose=-1)</pre></div> </div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=5, estimator=LGBMClassifier(device='gpu', verbose=-1),\n",
       "                   param_distributions={'boosting_type': ['gbdt', 'dart'],\n",
       "                                        'colsample_bytree': [0.6, 0.8, 1.0],\n",
       "                                        'learning_rate': [0.01, 0.05, 0.1],\n",
       "                                        'max_depth': [-1, 10, 20, 30],\n",
       "                                        'min_child_weight': [1, 5, 10],\n",
       "                                        'min_split_gain': [0, 0.01, 0.1],\n",
       "                                        'n_estimators': [100, 500, 1000],\n",
       "                                        'num_leaves': [31, 63, 127],\n",
       "                                        'reg_alpha': [0, 0.1, 1],\n",
       "                                        'reg_lambda': [0, 0.1, 1],\n",
       "                                        'scale_pos_weight': [1, 10, 20],\n",
       "                                        'subsample': [0.6, 0.8, 1.0]},\n",
       "                   random_state=42, verbose=2)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Set up the RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(estimator=lgbm, param_distributions=param_grid, n_iter=10, cv=5, random_state=42, verbose=2)\n",
    "\n",
    "# Fit the RandomizedSearchCV on the imputed training data\n",
    "random_search.fit(X_train_np, y_train_np)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found:  {'subsample': 0.8, 'scale_pos_weight': 1, 'reg_lambda': 0.1, 'reg_alpha': 1, 'num_leaves': 127, 'n_estimators': 1000, 'min_split_gain': 0, 'min_child_weight': 1, 'max_depth': -1, 'learning_rate': 0.1, 'colsample_bytree': 0.8, 'boosting_type': 'gbdt'}\n",
      "Best cross-validation score:  0.8057180813073165\n",
      "Test set score of the best model:  0.8078507556495158\n"
     ]
    }
   ],
   "source": [
    "print(\"Best parameters found: \", random_search.best_params_)\n",
    "print(\"Best cross-validation score: \", random_search.best_score_)\n",
    "\n",
    "# Evaluate the best model on the imputed test set\n",
    "best_model = random_search.best_estimator_\n",
    "test_score = best_model.score(X_test_np, y_test_np)\n",
    "print(\"Test set score of the best model: \", test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm=LGBMClassifier(verbose=-1,device='gpu',**random_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from cuml.ensemble import RandomForestClassifier as cuRF\n",
    "from cuml.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, matthews_corrcoef, precision_recall_fscore_support,\n",
    "    classification_report, confusion_matrix\n",
    ")\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import os\n",
    "import joblib\n",
    "import cudf\n",
    "import cupy as cp\n",
    "\n",
    "def evaluate_classifier_with_stratified_smote(X_train, y_train, X_test, y_test, classifier, num_folds=10, save_path=None, model_name=None):\n",
    "    k_fold = StratifiedKFold(n_splits=num_folds, shuffle=True, random_state=0)\n",
    "\n",
    "    accuracies_val = []\n",
    "    accuracies_train = []\n",
    "    train_scores = []\n",
    "    val_scores = []\n",
    "    train_mcc = []\n",
    "    val_mcc = []\n",
    "    train_f1 = []\n",
    "    val_f1 = []\n",
    "    train_precision = []\n",
    "    val_precision = []\n",
    "    train_recall = []\n",
    "    val_recall = []\n",
    "\n",
    "    X_train = X_train.to_pandas()\n",
    "    y_train = y_train.to_pandas()\n",
    "    X_test = X_test.to_pandas()\n",
    "    y_test = y_test.to_pandas()\n",
    "\n",
    "    for fold_idx, (train_indices, val_indices) in enumerate(k_fold.split(X_train, y_train), 1):\n",
    "        train_indices = cp.asnumpy(train_indices)\n",
    "        val_indices = cp.asnumpy(val_indices)\n",
    "\n",
    "        X_fold_train, X_fold_val = X_train.iloc[train_indices], X_train.iloc[val_indices]\n",
    "        y_fold_train, y_fold_val = y_train.iloc[train_indices], y_train.iloc[val_indices]\n",
    "\n",
    "        smote = SMOTE()\n",
    "        X_fold_train_resampled, y_fold_train_resampled = smote.fit_resample(X_fold_train, y_fold_train)\n",
    "\n",
    "        classifier.fit(X_fold_train_resampled, y_fold_train_resampled)\n",
    "\n",
    "        y_train_pred = classifier.predict(X_fold_train_resampled)\n",
    "        train_score = accuracy_score(y_fold_train_resampled, y_train_pred)\n",
    "        train_scores.append(train_score)\n",
    "\n",
    "        fold_accuracy_train = accuracy_score(y_fold_train_resampled, y_train_pred)\n",
    "        accuracies_train.append(fold_accuracy_train)\n",
    "\n",
    "        train_mcc.append(matthews_corrcoef(y_fold_train_resampled, y_train_pred))\n",
    "        train_f1.append(precision_recall_fscore_support(y_fold_train_resampled, y_train_pred, average='weighted')[2])\n",
    "        precision, recall, _, _ = precision_recall_fscore_support(y_fold_train_resampled, y_train_pred, average='weighted')\n",
    "        train_precision.append(precision)\n",
    "        train_recall.append(recall)\n",
    "\n",
    "        y_val_pred = classifier.predict(X_fold_val)\n",
    "        val_score = accuracy_score(y_fold_val, y_val_pred)\n",
    "        val_scores.append(val_score)\n",
    "\n",
    "        fold_accuracy_val = accuracy_score(y_fold_val, y_val_pred)\n",
    "        accuracies_val.append(fold_accuracy_val)\n",
    "\n",
    "        val_mcc.append(matthews_corrcoef(y_fold_val, y_val_pred))\n",
    "        val_f1.append(precision_recall_fscore_support(y_fold_val, y_val_pred, average='weighted')[2])\n",
    "        precision, recall, _, _ = precision_recall_fscore_support(y_fold_val, y_val_pred, average='weighted')\n",
    "        val_precision.append(precision)\n",
    "        val_recall.append(recall)\n",
    "\n",
    "    average_accuracy_val = sum(accuracies_val) / num_folds\n",
    "    print(f'Average Accuracy Val K-Fold: {average_accuracy_val * 100:.4f}')\n",
    "\n",
    "    average_accuracy_train = sum(accuracies_train) / num_folds\n",
    "    print(f'Average Accuracy Train K-Fold: {average_accuracy_train * 100:.4f}')\n",
    "\n",
    "    average_mcc_val = sum(val_mcc) / num_folds\n",
    "    print(f'Average MCC Val K-Fold: {average_mcc_val:.4f}')\n",
    "\n",
    "    average_mcc_train = sum(train_mcc) / num_folds\n",
    "    print(f'Average MCC Train K-Fold: {average_mcc_train:.4f}')\n",
    "\n",
    "    average_f1_val = sum(val_f1) / num_folds\n",
    "    print(f'Average F1 Score Val K-Fold: {average_f1_val:.4f}')\n",
    "\n",
    "    average_f1_train = sum(train_f1) / num_folds\n",
    "    print(f'Average F1 Score Train K-Fold: {average_f1_train:.4f}')\n",
    "\n",
    "    average_precision_val = sum(val_precision) / num_folds\n",
    "    print(f'Average Precision Val K-Fold: {average_precision_val:.4f}')\n",
    "\n",
    "    average_precision_train = sum(train_precision) / num_folds\n",
    "    print(f'Average Precision Train K-Fold: {average_precision_train:.4f}')\n",
    "\n",
    "    average_recall_val = sum(val_recall) / num_folds\n",
    "    print(f'Average Recall Val K-Fold: {average_recall_val:.4f}')\n",
    "\n",
    "    average_recall_train = sum(train_recall) / num_folds\n",
    "    print(f'Average Recall Train K-Fold: {average_recall_train:.4f}')\n",
    "\n",
    "    y_pred = classifier.predict(X_test)\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f'Accuracy Test: {accuracy * 100:.2f}%')\n",
    "\n",
    "    test_mcc = matthews_corrcoef(y_test, y_pred)\n",
    "    print(f'MCC Test: {test_mcc:.4f}')\n",
    "\n",
    "    test_f1 = precision_recall_fscore_support(y_test, y_pred, average='weighted')[2]\n",
    "    print(f'F1 Score Test: {test_f1:.4f}')\n",
    "\n",
    "    test_precision, test_recall, _, _ = precision_recall_fscore_support(y_test, y_pred, average='weighted')\n",
    "    print(f'Precision Test: {test_precision:.4f}')\n",
    "    print(f'Recall Test: {test_recall:.4f}')\n",
    "\n",
    "    class_report = classification_report(y_test, y_pred)\n",
    "    print('Classification Report:')\n",
    "    print(class_report)\n",
    "\n",
    "    conf_matrix_test = confusion_matrix(y_test, y_pred)\n",
    "    print('Confusion Matrix Test:')\n",
    "    print(conf_matrix_test)\n",
    "\n",
    "    if save_path and model_name:\n",
    "        output_filename = os.path.join(save_path, f\"{model_name}_outputs.txt\")\n",
    "        with open(output_filename, 'w') as f:\n",
    "            f.write(f'Average Accuracy Val K-Fold: {average_accuracy_val * 100:.4f}\\n')\n",
    "            f.write(f'Average Accuracy Train K-Fold: {average_accuracy_train * 100:.4f}\\n')\n",
    "            f.write(f'Average MCC Val K-Fold: {average_mcc_val:.4f}\\n')\n",
    "            f.write(f'Average MCC Train K-Fold: {average_mcc_train:.4f}\\n')\n",
    "            f.write(f'Average F1 Score Val K-Fold: {average_f1_val:.4f}\\n')\n",
    "            f.write(f'Average F1 Score Train K-Fold: {average_f1_train:.4f}\\n')\n",
    "            f.write(f'Average Precision Val K-Fold: {average_precision_val:.4f}\\n')\n",
    "            f.write(f'Average Precision Train K-Fold: {average_precision_train:.4f}\\n')\n",
    "            f.write(f'Average Recall Val K-Fold: {average_recall_val:.4f}\\n')\n",
    "            f.write(f'Average Recall Train K-Fold: {average_recall_train:.4f}\\n')\n",
    "            f.write(f'Accuracy Test: {accuracy * 100:.2f}%\\n')\n",
    "            f.write(f'MCC Test: {test_mcc:.4f}\\n')\n",
    "            f.write(f'F1 Score Test: {test_f1:.4f}\\n')\n",
    "            f.write(f'Precision Test: {test_precision:.4f}\\n')\n",
    "            f.write(f'Recall Test: {test_recall:.4f}\\n')\n",
    "            f.write('Classification Report:\\n')\n",
    "            f.write(class_report + '\\n')\n",
    "            f.write('Confusion Matrix Test:\\n')\n",
    "            f.write(str(conf_matrix_test) + '\\n')\n",
    "        print(f\"Outputs saved to: {output_filename}\")\n",
    "        joblib.dump(classifier, os.path.join(save_path, f\"{model_name}.joblib\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Accuracy Val K-Fold: 75.5174\n",
      "Average Accuracy Train K-Fold: 88.8461\n",
      "Average MCC Val K-Fold: 0.5807\n",
      "Average MCC Train K-Fold: 0.8548\n",
      "Average F1 Score Val K-Fold: 0.7606\n",
      "Average F1 Score Train K-Fold: 0.8895\n",
      "Average Precision Val K-Fold: 0.7806\n",
      "Average Precision Train K-Fold: 0.9001\n",
      "Average Recall Val K-Fold: 0.7552\n",
      "Average Recall Train K-Fold: 0.8885\n",
      "Accuracy Test: 75.36%\n",
      "MCC Test: 0.5776\n",
      "F1 Score Test: 0.7585\n",
      "Precision Test: 0.7781\n",
      "Recall Test: 0.7536\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.49      0.84      0.62     20092\n",
      "         2.0       0.83      0.62      0.71     11288\n",
      "         3.0       0.66      0.58      0.62     34605\n",
      "         4.0       0.86      0.81      0.83    109030\n",
      "\n",
      "    accuracy                           0.75    175015\n",
      "   macro avg       0.71      0.71      0.70    175015\n",
      "weighted avg       0.78      0.75      0.76    175015\n",
      "\n",
      "Confusion Matrix Test:\n",
      "[[16895   130   957  2110]\n",
      " [ 3519  6955    94   720]\n",
      " [ 3196   238 19999 11172]\n",
      " [10673  1009  9314 88034]]\n",
      "Outputs saved to: /home/pavit21178/Nalin_OFF/Models_44/LGBM/LGBM_strat_Kfold_Smote_outputs.txt\n"
     ]
    }
   ],
   "source": [
    "evaluate_classifier_with_stratified_smote(X_train, y_train, X_test, y_test, lgbm, num_folds=2, save_path=\"/home/pavit21178/Nalin_OFF/Models_44/LGBM\", model_name=\"LGBM_strat_Kfold_Smote\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from cuml.ensemble import RandomForestClassifier as cuRF\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, matthews_corrcoef, precision_recall_fscore_support,\n",
    "    classification_report, confusion_matrix\n",
    ")\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import os\n",
    "import joblib\n",
    "import cudf\n",
    "import cupy as cp\n",
    "\n",
    "def evaluate_classifier_with_kfold_smote(X_train, y_train, X_test, y_test, classifier, num_folds=10, save_path=None, model_name=None):\n",
    "    k_fold = KFold(n_splits=num_folds, shuffle=True, random_state=0)\n",
    "\n",
    "    accuracies_val = []\n",
    "    accuracies_train = []\n",
    "    train_scores = []\n",
    "    val_scores = []\n",
    "    train_mcc = []\n",
    "    val_mcc = []\n",
    "    train_f1 = []\n",
    "    val_f1 = []\n",
    "    train_precision = []\n",
    "    val_precision = []\n",
    "    train_recall = []\n",
    "    val_recall = []\n",
    "\n",
    "    X_train = X_train.to_pandas()\n",
    "    y_train = y_train.to_pandas()\n",
    "    X_test = X_test.to_pandas()\n",
    "    y_test = y_test.to_pandas()\n",
    "\n",
    "    for fold_idx, (train_indices, val_indices) in enumerate(k_fold.split(X_train, y_train), 1):\n",
    "        train_indices = cp.asnumpy(train_indices)\n",
    "        val_indices = cp.asnumpy(val_indices)\n",
    "\n",
    "        X_fold_train, X_fold_val = X_train.iloc[train_indices], X_train.iloc[val_indices]\n",
    "        y_fold_train, y_fold_val = y_train.iloc[train_indices], y_train.iloc[val_indices]\n",
    "\n",
    "        smote = SMOTE()\n",
    "        X_fold_train_resampled, y_fold_train_resampled = smote.fit_resample(X_fold_train, y_fold_train)\n",
    "\n",
    "        classifier.fit(X_fold_train_resampled, y_fold_train_resampled)\n",
    "\n",
    "        y_train_pred = classifier.predict(X_fold_train_resampled)\n",
    "        train_score = accuracy_score(y_fold_train_resampled, y_train_pred)\n",
    "        train_scores.append(train_score)\n",
    "\n",
    "        fold_accuracy_train = accuracy_score(y_fold_train_resampled, y_train_pred)\n",
    "        accuracies_train.append(fold_accuracy_train)\n",
    "\n",
    "        train_mcc.append(matthews_corrcoef(y_fold_train_resampled, y_train_pred))\n",
    "        train_f1.append(precision_recall_fscore_support(y_fold_train_resampled, y_train_pred, average='weighted')[2])\n",
    "        precision, recall, _, _ = precision_recall_fscore_support(y_fold_train_resampled, y_train_pred, average='weighted')\n",
    "        train_precision.append(precision)\n",
    "        train_recall.append(recall)\n",
    "\n",
    "        y_val_pred = classifier.predict(X_fold_val)\n",
    "        val_score = accuracy_score(y_fold_val, y_val_pred)\n",
    "        val_scores.append(val_score)\n",
    "\n",
    "        fold_accuracy_val = accuracy_score(y_fold_val, y_val_pred)\n",
    "        accuracies_val.append(fold_accuracy_val)\n",
    "\n",
    "        val_mcc.append(matthews_corrcoef(y_fold_val, y_val_pred))\n",
    "        val_f1.append(precision_recall_fscore_support(y_fold_val, y_val_pred, average='weighted')[2])\n",
    "        precision, recall, _, _ = precision_recall_fscore_support(y_fold_val, y_val_pred, average='weighted')\n",
    "        val_precision.append(precision)\n",
    "        val_recall.append(recall)\n",
    "\n",
    "    average_accuracy_val = sum(accuracies_val) / num_folds\n",
    "    print(f'Average Accuracy Val K-Fold: {average_accuracy_val * 100:.4f}')\n",
    "\n",
    "    average_accuracy_train = sum(accuracies_train) / num_folds\n",
    "    print(f'Average Accuracy Train K-Fold: {average_accuracy_train * 100:.4f}')\n",
    "\n",
    "    average_mcc_val = sum(val_mcc) / num_folds\n",
    "    print(f'Average MCC Val K-Fold: {average_mcc_val:.4f}')\n",
    "\n",
    "    average_mcc_train = sum(train_mcc) / num_folds\n",
    "    print(f'Average MCC Train K-Fold: {average_mcc_train:.4f}')\n",
    "\n",
    "    average_f1_val = sum(val_f1) / num_folds\n",
    "    print(f'Average F1 Score Val K-Fold: {average_f1_val:.4f}')\n",
    "\n",
    "    average_f1_train = sum(train_f1) / num_folds\n",
    "    print(f'Average F1 Score Train K-Fold: {average_f1_train:.4f}')\n",
    "\n",
    "    average_precision_val = sum(val_precision) / num_folds\n",
    "    print(f'Average Precision Val K-Fold: {average_precision_val:.4f}')\n",
    "\n",
    "    average_precision_train = sum(train_precision) / num_folds\n",
    "    print(f'Average Precision Train K-Fold: {average_precision_train:.4f}')\n",
    "\n",
    "    average_recall_val = sum(val_recall) / num_folds\n",
    "    print(f'Average Recall Val K-Fold: {average_recall_val:.4f}')\n",
    "\n",
    "    average_recall_train = sum(train_recall) / num_folds\n",
    "    print(f'Average Recall Train K-Fold: {average_recall_train:.4f}')\n",
    "\n",
    "    y_pred = classifier.predict(X_test)\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f'Accuracy Test: {accuracy * 100:.2f}%')\n",
    "\n",
    "    test_mcc = matthews_corrcoef(y_test, y_pred)\n",
    "    print(f'MCC Test: {test_mcc:.4f}')\n",
    "\n",
    "    test_f1 = precision_recall_fscore_support(y_test, y_pred, average='weighted')[2]\n",
    "    print(f'F1 Score Test: {test_f1:.4f}')\n",
    "\n",
    "    test_precision, test_recall, _, _ = precision_recall_fscore_support(y_test, y_pred, average='weighted')\n",
    "    print(f'Precision Test: {test_precision:.4f}')\n",
    "    print(f'Recall Test: {test_recall:.4f}')\n",
    "\n",
    "    class_report = classification_report(y_test, y_pred)\n",
    "    print('Classification Report:')\n",
    "    print(class_report)\n",
    "\n",
    "    conf_matrix_test = confusion_matrix(y_test, y_pred)\n",
    "    print('Confusion Matrix Test:')\n",
    "    print(conf_matrix_test)\n",
    "\n",
    "    if save_path and model_name:\n",
    "        output_filename = os.path.join(save_path, f\"{model_name}_outputs.txt\")\n",
    "        with open(output_filename, 'w') as f:\n",
    "            f.write(f'Average Accuracy Val K-Fold: {average_accuracy_val * 100:.4f}\\n')\n",
    "            f.write(f'Average Accuracy Train K-Fold: {average_accuracy_train * 100:.4f}\\n')\n",
    "            f.write(f'Average MCC Val K-Fold: {average_mcc_val:.4f}\\n')\n",
    "            f.write(f'Average MCC Train K-Fold: {average_mcc_train:.4f}\\n')\n",
    "            f.write(f'Average F1 Score Val K-Fold: {average_f1_val:.4f}\\n')\n",
    "            f.write(f'Average F1 Score Train K-Fold: {average_f1_train:.4f}\\n')\n",
    "            f.write(f'Average Precision Val K-Fold: {average_precision_val:.4f}\\n')\n",
    "            f.write(f'Average Precision Train K-Fold: {average_precision_train:.4f}\\n')\n",
    "            f.write(f'Average Recall Val K-Fold: {average_recall_val:.4f}\\n')\n",
    "            f.write(f'Average Recall Train K-Fold: {average_recall_train:.4f}\\n')\n",
    "            f.write(f'Accuracy Test: {accuracy * 100:.2f}%\\n')\n",
    "            f.write(f'MCC Test: {test_mcc:.4f}\\n')\n",
    "            f.write(f'F1 Score Test: {test_f1:.4f}\\n')\n",
    "            f.write(f'Precision Test: {test_precision:.4f}\\n')\n",
    "            f.write(f'Recall Test: {test_recall:.4f}\\n')\n",
    "            f.write('Classification Report:\\n')\n",
    "            f.write(class_report + '\\n')\n",
    "            f.write('Confusion Matrix Test:\\n')\n",
    "            f.write(str(conf_matrix_test) + '\\n')\n",
    "        print(f\"Outputs saved to: {output_filename}\")\n",
    "        joblib.dump(classifier, os.path.join(save_path, f\"{model_name}.joblib\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Accuracy Val K-Fold: 75.6085\n",
      "Average Accuracy Train K-Fold: 89.0428\n",
      "Average MCC Val K-Fold: 0.5831\n",
      "Average MCC Train K-Fold: 0.8575\n",
      "Average F1 Score Val K-Fold: 0.7621\n",
      "Average F1 Score Train K-Fold: 0.8910\n",
      "Average Precision Val K-Fold: 0.7822\n",
      "Average Precision Train K-Fold: 0.9014\n",
      "Average Recall Val K-Fold: 0.7561\n",
      "Average Recall Train K-Fold: 0.8904\n",
      "Accuracy Test: 75.59%\n",
      "MCC Test: 0.5838\n",
      "F1 Score Test: 0.7621\n",
      "Precision Test: 0.7827\n",
      "Recall Test: 0.7559\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.76      0.68      0.72     20092\n",
      "         2.0       0.42      0.91      0.58     11288\n",
      "         3.0       0.66      0.58      0.62     34605\n",
      "         4.0       0.86      0.81      0.84    109030\n",
      "\n",
      "    accuracy                           0.76    175015\n",
      "   macro avg       0.68      0.75      0.69    175015\n",
      "weighted avg       0.78      0.76      0.76    175015\n",
      "\n",
      "Confusion Matrix Test:\n",
      "[[13699  3278  1010  2105]\n",
      " [  162 10309    92   725]\n",
      " [ 1493  1885 19971 11256]\n",
      " [ 2591  8958  9172 88309]]\n",
      "Outputs saved to: /home/pavit21178/Nalin_OFF/Models_44/LGBM/LGBM_Kfold_Smote_outputs.txt\n"
     ]
    }
   ],
   "source": [
    "evaluate_classifier_with_kfold_smote(X_train, y_train, X_test, y_test, lgbm, num_folds=2, save_path=\"/home/pavit21178/Nalin_OFF/Models_44/LGBM\", model_name=\"LGBM_Kfold_Smote\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from cuml.ensemble import RandomForestClassifier as cuRF\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, matthews_corrcoef, precision_recall_fscore_support,\n",
    "    classification_report, confusion_matrix\n",
    ")\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import os\n",
    "import joblib\n",
    "import cudf\n",
    "import cupy as cp\n",
    "\n",
    "def evaluate_classifier_with_stratified(X_train, y_train, X_test, y_test, classifier, num_folds=10, save_path=None, model_name=None):\n",
    "    k_fold = StratifiedKFold(n_splits=num_folds, shuffle=True, random_state=0)\n",
    "\n",
    "    accuracies_val = []\n",
    "    accuracies_train = []\n",
    "    train_scores = []\n",
    "    val_scores = []\n",
    "    train_mcc = []\n",
    "    val_mcc = []\n",
    "    train_f1 = []\n",
    "    val_f1 = []\n",
    "    train_precision = []\n",
    "    val_precision = []\n",
    "    train_recall = []\n",
    "    val_recall = []\n",
    "\n",
    "    X_train = X_train.to_pandas()\n",
    "    y_train = y_train.to_pandas()\n",
    "    X_test = X_test.to_pandas()\n",
    "    y_test = y_test.to_pandas()\n",
    "\n",
    "    for fold_idx, (train_indices, val_indices) in enumerate(k_fold.split(X_train, y_train), 1):\n",
    "        train_indices = cp.asnumpy(train_indices)\n",
    "        val_indices = cp.asnumpy(val_indices)\n",
    "\n",
    "        X_fold_train, X_fold_val = X_train.iloc[train_indices], X_train.iloc[val_indices]\n",
    "        y_fold_train, y_fold_val = y_train.iloc[train_indices], y_train.iloc[val_indices]\n",
    "\n",
    "        X_fold_train_resampled, y_fold_train_resampled = X_fold_train, y_fold_train\n",
    "\n",
    "        classifier.fit(X_fold_train_resampled, y_fold_train_resampled)\n",
    "\n",
    "        y_train_pred = classifier.predict(X_fold_train_resampled)\n",
    "        train_score = accuracy_score(y_fold_train_resampled, y_train_pred)\n",
    "        train_scores.append(train_score)\n",
    "\n",
    "        fold_accuracy_train = accuracy_score(y_fold_train_resampled, y_train_pred)\n",
    "        accuracies_train.append(fold_accuracy_train)\n",
    "\n",
    "        train_mcc.append(matthews_corrcoef(y_fold_train_resampled, y_train_pred))\n",
    "        train_f1.append(precision_recall_fscore_support(y_fold_train_resampled, y_train_pred, average='weighted')[2])\n",
    "        precision, recall, _, _ = precision_recall_fscore_support(y_fold_train_resampled, y_train_pred, average='weighted')\n",
    "        train_precision.append(precision)\n",
    "        train_recall.append(recall)\n",
    "\n",
    "        y_val_pred = classifier.predict(X_fold_val)\n",
    "        val_score = accuracy_score(y_fold_val, y_val_pred)\n",
    "        val_scores.append(val_score)\n",
    "\n",
    "        fold_accuracy_val = accuracy_score(y_fold_val, y_val_pred)\n",
    "        accuracies_val.append(fold_accuracy_val)\n",
    "\n",
    "        val_mcc.append(matthews_corrcoef(y_fold_val, y_val_pred))\n",
    "        val_f1.append(precision_recall_fscore_support(y_fold_val, y_val_pred, average='weighted')[2])\n",
    "        precision, recall, _, _ = precision_recall_fscore_support(y_fold_val, y_val_pred, average='weighted')\n",
    "        val_precision.append(precision)\n",
    "        val_recall.append(recall)\n",
    "\n",
    "    average_accuracy_val = sum(accuracies_val) / num_folds\n",
    "    print(f'Average Accuracy Val K-Fold: {average_accuracy_val * 100:.4f}')\n",
    "\n",
    "    average_accuracy_train = sum(accuracies_train) / num_folds\n",
    "    print(f'Average Accuracy Train K-Fold: {average_accuracy_train * 100:.4f}')\n",
    "\n",
    "    average_mcc_val = sum(val_mcc) / num_folds\n",
    "    print(f'Average MCC Val K-Fold: {average_mcc_val:.4f}')\n",
    "\n",
    "    average_mcc_train = sum(train_mcc) / num_folds\n",
    "    print(f'Average MCC Train K-Fold: {average_mcc_train:.4f}')\n",
    "\n",
    "    average_f1_val = sum(val_f1) / num_folds\n",
    "    print(f'Average F1 Score Val K-Fold: {average_f1_val:.4f}')\n",
    "\n",
    "    average_f1_train = sum(train_f1) / num_folds\n",
    "    print(f'Average F1 Score Train K-Fold: {average_f1_train:.4f}')\n",
    "\n",
    "    average_precision_val = sum(val_precision) / num_folds\n",
    "    print(f'Average Precision Val K-Fold: {average_precision_val:.4f}')\n",
    "\n",
    "    average_precision_train = sum(train_precision) / num_folds\n",
    "    print(f'Average Precision Train K-Fold: {average_precision_train:.4f}')\n",
    "\n",
    "    average_recall_val = sum(val_recall) / num_folds\n",
    "    print(f'Average Recall Val K-Fold: {average_recall_val:.4f}')\n",
    "\n",
    "    average_recall_train = sum(train_recall) / num_folds\n",
    "    print(f'Average Recall Train K-Fold: {average_recall_train:.4f}')\n",
    "\n",
    "    y_pred = classifier.predict(X_test)\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f'Accuracy Test: {accuracy * 100:.2f}%')\n",
    "\n",
    "    test_mcc = matthews_corrcoef(y_test, y_pred)\n",
    "    print(f'MCC Test: {test_mcc:.4f}')\n",
    "\n",
    "    test_f1 = precision_recall_fscore_support(y_test, y_pred, average='weighted')[2]\n",
    "    print(f'F1 Score Test: {test_f1:.4f}')\n",
    "\n",
    "    test_precision, test_recall, _, _ = precision_recall_fscore_support(y_test, y_pred, average='weighted')\n",
    "    print(f'Precision Test: {test_precision:.4f}')\n",
    "    print(f'Recall Test: {test_recall:.4f}')\n",
    "\n",
    "    class_report = classification_report(y_test, y_pred)\n",
    "    print('Classification Report:')\n",
    "    print(class_report)\n",
    "\n",
    "    conf_matrix_test = confusion_matrix(y_test, y_pred)\n",
    "    print('Confusion Matrix Test:')\n",
    "    print(conf_matrix_test)\n",
    "\n",
    "    if save_path and model_name:\n",
    "        output_filename = os.path.join(save_path, f\"{model_name}_outputs.txt\")\n",
    "        with open(output_filename, 'w') as f:\n",
    "            f.write(f'Average Accuracy Val K-Fold: {average_accuracy_val * 100:.4f}\\n')\n",
    "            f.write(f'Average Accuracy Train K-Fold: {average_accuracy_train * 100:.4f}\\n')\n",
    "            f.write(f'Average MCC Val K-Fold: {average_mcc_val:.4f}\\n')\n",
    "            f.write(f'Average MCC Train K-Fold: {average_mcc_train:.4f}\\n')\n",
    "            f.write(f'Average F1 Score Val K-Fold: {average_f1_val:.4f}\\n')\n",
    "            f.write(f'Average F1 Score Train K-Fold: {average_f1_train:.4f}\\n')\n",
    "            f.write(f'Average Precision Val K-Fold: {average_precision_val:.4f}\\n')\n",
    "            f.write(f'Average Precision Train K-Fold: {average_precision_train:.4f}\\n')\n",
    "            f.write(f'Average Recall Val K-Fold: {average_recall_val:.4f}\\n')\n",
    "            f.write(f'Average Recall Train K-Fold: {average_recall_train:.4f}\\n')\n",
    "            f.write(f'Accuracy Test: {accuracy * 100:.2f}%\\n')\n",
    "            f.write(f'MCC Test: {test_mcc:.4f}\\n')\n",
    "            f.write(f'F1 Score Test: {test_f1:.4f}\\n')\n",
    "            f.write(f'Precision Test: {test_precision:.4f}\\n')\n",
    "            f.write(f'Recall Test: {test_recall:.4f}\\n')\n",
    "            f.write('Classification Report:\\n')\n",
    "            f.write(class_report + '\\n')\n",
    "            f.write('Confusion Matrix Test:\\n')\n",
    "            f.write(str(conf_matrix_test) + '\\n')\n",
    "        print(f\"Outputs saved to: {output_filename}\")\n",
    "        joblib.dump(classifier, os.path.join(save_path, f\"{model_name}.joblib\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Accuracy Val K-Fold: 80.0978\n",
      "Average Accuracy Train K-Fold: 89.1759\n",
      "Average MCC Val K-Fold: 0.6200\n",
      "Average MCC Train K-Fold: 0.7995\n",
      "Average F1 Score Val K-Fold: 0.7912\n",
      "Average F1 Score Train K-Fold: 0.8883\n",
      "Average Precision Val K-Fold: 0.7998\n",
      "Average Precision Train K-Fold: 0.8964\n",
      "Average Recall Val K-Fold: 0.8010\n",
      "Average Recall Train K-Fold: 0.8918\n",
      "Accuracy Test: 80.01%\n",
      "MCC Test: 0.6190\n",
      "F1 Score Test: 0.7902\n",
      "Precision Test: 0.7988\n",
      "Recall Test: 0.8001\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.82      0.66      0.73     20092\n",
      "         2.0       0.89      0.61      0.72     11288\n",
      "         3.0       0.74      0.53      0.62     34605\n",
      "         4.0       0.80      0.93      0.86    109030\n",
      "\n",
      "    accuracy                           0.80    175015\n",
      "   macro avg       0.81      0.68      0.73    175015\n",
      "weighted avg       0.80      0.80      0.79    175015\n",
      "\n",
      "Confusion Matrix Test:\n",
      "[[ 13305    116    934   5737]\n",
      " [   122   6846     83   4237]\n",
      " [  1194    159  18337  14915]\n",
      " [  1627    593   5275 101535]]\n",
      "Outputs saved to: /home/pavit21178/Nalin_OFF/Models_44/LGBM/LGBM_strat_outputs.txt\n"
     ]
    }
   ],
   "source": [
    "evaluate_classifier_with_stratified(X_train, y_train, X_test, y_test, lgbm, num_folds=2, save_path=\"/home/pavit21178/Nalin_OFF/Models_44/LGBM\", model_name=\"LGBM_strat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rapids-24.06",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
